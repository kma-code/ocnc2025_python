{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "third-nepal",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "traditional-crisis",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# color-blind color scheme\n",
    "plt.style.use('tableau-colorblind10')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "downtown-graduate",
   "metadata": {
    "heading_collapsed": "true",
    "tags": []
   },
   "source": [
    "## Load in old code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dangerous-simpson",
   "metadata": {},
   "source": [
    "We build on the previous notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "democratic-latvia",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LIF_neuron:\n",
    "    # initialize a neuron class\n",
    "    # provided parameter dictionary params\n",
    "    def __init__(self, params):\n",
    "        # attach parameters to object\n",
    "        self.V_th, self.V_reset = params['V_th'], params['V_reset']   \n",
    "        self.tau_m, self.g_L = params['tau_m'], params['g_L']        \n",
    "        self.V_init, self.V_L = params['V_init'], params['V_L']       \n",
    "        self.dt = params['dt']\n",
    "        self.tau_ref = params['tau_ref']\n",
    "\n",
    "        # initialize voltage and current\n",
    "        self.v = 0.0\n",
    "        # time steps since last spike\n",
    "        self.refractory_counter = 0\n",
    "    \n",
    "    def LIF_step(self, I):\n",
    "        \"\"\"\n",
    "            Perform one step of the LIF dynamics\n",
    "        \"\"\"\n",
    "        \n",
    "        currently_spiking = False\n",
    "        \n",
    "        if self.refractory_counter > 0:\n",
    "            # if the neuron is still refractory\n",
    "            self.v = self.V_reset\n",
    "            self.refractory_counter = self.refractory_counter - 1\n",
    "        elif self.v >= self.V_th:\n",
    "            # if v is above threshold,\n",
    "            # reset voltage and record spike event\n",
    "            currently_spiking = True\n",
    "            self.v = self.V_reset\n",
    "            self.refractory_counter = self.tau_ref/self.dt\n",
    "        else:\n",
    "            # else, integrate the current:\n",
    "            # calculate the increment of the membrane potential\n",
    "            dv = self.voltage_dynamics(I)\n",
    "            # update the membrane potential\n",
    "            self.v = self.v + dv\n",
    "\n",
    "        return self.v, currently_spiking\n",
    "    \n",
    "    def voltage_dynamics(self, I):\n",
    "        \"\"\"\n",
    "            Calulcates one step of the LI dynamics\n",
    "        \"\"\"\n",
    "        dv = (-(self.v-self.V_L) + I/self.g_L) * (self.dt/self.tau_m)\n",
    "        return dv\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hybrid-distribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define new class as child of old class\n",
    "class ExpLIF_neuron(LIF_neuron):\n",
    "    def __init__(self, params):\n",
    "        # build on LIF neuron with same settings\n",
    "        # (this will run __init__ of the parent class)\n",
    "        super().__init__(params)\n",
    "        \n",
    "        # we only need to attach additional variables:\n",
    "        self.DeltaT = params['DeltaT']\n",
    "        self.V_exp_trigger = params['V_exp_trigger']\n",
    "    \n",
    "    # now we can just    \n",
    "    def voltage_dynamics(self, I):\n",
    "        \"\"\"\n",
    "            Calulcates one step of the exp-LI dynamics\n",
    "        \"\"\"\n",
    "        dv = (-(self.v-self.V_L) + I/self.g_L + self.DeltaT * np.exp((self.v-self.V_exp_trigger)/self.DeltaT)) * (self.dt/self.tau_m)\n",
    "        return dv\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "following-think",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExpLIF_population:\n",
    "    def __init__(self, params):\n",
    "        # attach parameters to object\n",
    "        self.V_th, self.V_reset = params['V_th'], params['V_reset']   \n",
    "        self.tau_m, self.g_L = params['tau_m'], params['g_L']        \n",
    "        self.V_init, self.V_L = params['V_init'], params['V_L']       \n",
    "        self.dt = params['dt']\n",
    "        self.tau_ref = params['tau_ref']\n",
    "        self.DeltaT = params['DeltaT']\n",
    "        self.V_exp_trigger = params['V_exp_trigger']\n",
    "        \n",
    "        # number of neurons\n",
    "        self.n_neurons = params[\"n_neurons\"]\n",
    "\n",
    "        # initialize voltages\n",
    "        self.v = np.zeros(self.n_neurons)\n",
    "        # time steps since last spike\n",
    "        self.refractory_counter = np.zeros(self.n_neurons)\n",
    "            \n",
    "    def LIF_step(self, I):\n",
    "        \"\"\"\n",
    "            Perform one step of the LIF dynamics\n",
    "        \"\"\"\n",
    "        \n",
    "        currently_spiking = np.array([False for _ in range(self.n_neurons)])\n",
    "        \n",
    "        # This is where the magic happens: numpy indexing.\n",
    "        # first, we need to get indices of neurons which\n",
    "        # are refractory, above threshold or neither:\n",
    "        idx_ref = np.where(self.refractory_counter > 0)[0]\n",
    "        idx_spk = np.where(self.v > self.V_th)[0]\n",
    "        idx_else = np.where((self.refractory_counter <= 0) & (self.v <= self.V_th))[0]\n",
    "        \n",
    "        # if the neuron is still refractory\n",
    "        self.v[idx_ref] = self.V_reset\n",
    "        self.refractory_counter[idx_ref] -= 1\n",
    "        \n",
    "        # if v is above threshold,\n",
    "        # reset voltage and record spike event\n",
    "        currently_spiking[idx_spk] = True\n",
    "        self.v[idx_spk] = self.V_reset\n",
    "        self.refractory_counter[idx_spk] = self.tau_ref/self.dt\n",
    "        \n",
    "        # calculate the increment of the membrane potential\n",
    "        dv = self.voltage_dynamics(I)\n",
    "        # update the membrane potential only for non-spiking neurons\n",
    "        self.v[idx_else] += dv[idx_else]\n",
    "\n",
    "        return self.v, currently_spiking\n",
    "        \n",
    "    def voltage_dynamics(self, I):\n",
    "        \"\"\"\n",
    "            Calulcates one step of the exp-LI dynamics\n",
    "        \"\"\"\n",
    "        # Fortunately, this code already enabled vectors, due to numpy magic.\n",
    "        dv = (-(self.v-self.V_L) + I/self.g_L + self.DeltaT * np.exp((self.v-self.V_exp_trigger)/self.DeltaT)) * (self.dt/self.tau_m)\n",
    "        return dv\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinated-wyoming",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "### typical neuron parameters###\n",
    "params['V_th']    = -55. # spike threshold [mV]\n",
    "params['V_reset'] = -75. #reset potential [mV]\n",
    "params['tau_m']   = 10. # membrane time constant [ms]\n",
    "params['g_L']     = 10. #leak conductance [nS]\n",
    "params['V_init']  = -65. # initial potential [mV]\n",
    "params['V_L']     = -75. #leak reversal potential [mV]\n",
    "params['tau_ref']    = 2. # refractory time (ms)\n",
    "params['dt'] = .1  # Simulation time step [ms]\n",
    "\n",
    "# additional parameters for ExpLIF neurons\n",
    "params['DeltaT'] = 10.0  # sharpness of exponential peak\n",
    "params['V_exp_trigger'] = -55. # threshold for exponential depolarization [mV]\n",
    "params['V_th'] = 0 # new reset threshold [mV]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "mental-humor",
   "metadata": {},
   "source": [
    "# Timeit and memory allocation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electoral-cause",
   "metadata": {},
   "source": [
    "The code we wrote works, but there several things that we can do to make it run faster. Let's also time it using the Jupyter cell magic `%%timeit`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-morrison",
   "metadata": {},
   "outputs": [],
   "source": [
    "params[\"n_neurons\"] = 1_000\n",
    "params[\"n_steps\"] = 10_000\n",
    "\n",
    "mean_I, std_I = 300, 300"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increasing-tuner",
   "metadata": {},
   "source": [
    "### Single neuron code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "upset-bailey",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I have commented these out because they can run quite slow\n",
    "\n",
    "# population1 = [ExpLIF_neuron(params) for _ in range(n_neurons)]\n",
    "\n",
    "# # these will now become lists of lists (neurons, time steps)\n",
    "# voltages_arr = []\n",
    "# spikes_arr = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "scenic-ethernet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit -n 1 -r 3\n",
    "\n",
    "# for i, neuron in enumerate(population1):\n",
    "#     voltages = []\n",
    "#     spikes = []\n",
    "# #     if i % 10 == 0:\n",
    "# #         print(f\"Working on neuron {i}\")\n",
    "#     for _ in range(params[\"n_steps\"]):\n",
    "#         I = np.random.normal(mean_I, std_I)\n",
    "#         v, s = neuron.LIF_step(I=I)\n",
    "#         voltages.append(v)\n",
    "#         spikes.append(s)\n",
    "#     voltages_arr.append(voltages.copy())\n",
    "#     spikes_arr.append(spikes.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operating-encounter",
   "metadata": {},
   "source": [
    "### Population code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "innocent-surface",
   "metadata": {},
   "outputs": [],
   "source": [
    "population2 = ExpLIF_population(params)\n",
    "\n",
    "# these will now become lists of lists (neurons, time steps)\n",
    "voltages_arr = []\n",
    "spikes_arr = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wanted-sacramento",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 1 -r 10\n",
    "\n",
    "for _ in range(params[\"n_steps\"]):\n",
    "    I = np.random.normal(mean_I, std_I, size=params[\"n_neurons\"])\n",
    "    v, s = population2.LIF_step(I=I)\n",
    "    voltages_arr.append(v.copy())\n",
    "    spikes_arr.append(s.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "certified-fraction",
   "metadata": {},
   "source": [
    "An important trick is knowing about memory allocation: by `append`ing to the lists, we are always creating a new object in memory.\n",
    "\n",
    "**For large arrays, this becomes very slow**.\n",
    "\n",
    "But because we know beforehand how long each simulation is, we can create the list beforehand and write into it during simulation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "western-conspiracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "population3 = ExpLIF_population(params)\n",
    "\n",
    "# these will now become lists of lists (neurons, time steps)\n",
    "voltages_arr = np.zeros((params[\"n_steps\"], params[\"n_neurons\"]))\n",
    "spikes_arr = np.zeros((params[\"n_steps\"], params[\"n_neurons\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interracial-cooler",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit -n 1 -r 10\n",
    "\n",
    "for i in range(params[\"n_steps\"]):\n",
    "    I = np.random.normal(mean_I, std_I, size=params[\"n_neurons\"])\n",
    "    voltages_arr[i], spikes_arr[i] = population3.LIF_step(I=I)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "informed-mongolia",
   "metadata": {},
   "source": [
    "(Actually, our example here is so small that you will barely see a difference; but for large arrays, I've seend a difference of 300% in simulation speed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pediatric-allowance",
   "metadata": {},
   "source": [
    "Let's look at some spike rasters and a histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-equipment",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_range = (9000,10_000)\n",
    "for i in range(params[\"n_neurons\"]):\n",
    "    spike_times = spikes_arr[x_range[0]:x_range[1],i].nonzero()[0]\n",
    "    plt.scatter(spike_times + x_range[0], i*np.ones_like(spike_times), marker='.', c='black')\n",
    "plt.xlabel('Time step')\n",
    "plt.ylabel('# Neuron')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "delayed-panic",
   "metadata": {},
   "source": [
    "# Realizing when it is time to go from a Jupyter notebook to a standalone script"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "casual-brain",
   "metadata": {},
   "source": [
    "As we have seen, the simulations are becoming larger, with more populations and variables which get overwritten. \n",
    "\n",
    "Jupyter notebooks are great for prototyping, but at some point, we have to switch to a proper script. Some reasons are:\n",
    "- reproducibility and debugging: a common issue with Jupyter notebooks or similar IDEs is that you don't notice when old variables are in use.\n",
    "You may have restarted the kernel and noticed some plot looks different, without an obvious way to backtrack what was different in the previous execution.\n",
    "- clarity: scripts can be organized more easily into modules, making it easier to understand which parts being called at a given time.\n",
    "- version control: Jupyter notebooks can be a headache for collaborations. When you execute a notebook, the IDs of all cells change, even if you haven't actually modified their content. `Git` is not able to tell these apart, and your collaborators/future you will have to dig through every line to see if something has actually changed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alpha-evans",
   "metadata": {},
   "source": [
    "Take a look at `standalone_script.py`, which implements the populations using a parameter file `params.yaml`. Familiarize yourself with both. You can run it with `python standalone_script.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-fountain",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "requested-butter",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-sleeve",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "italic-breathing",
   "metadata": {},
   "source": [
    "# Multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funky-circuit",
   "metadata": {},
   "source": [
    "So far, we are using numpy in its simplest form: a single process running on CPU. We can take advantage of multicore systems by using multiprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "superior-custody",
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocess as mp   # for multiprocessing\n",
    "\n",
    "# declare the number of processes to start\n",
    "N_PROCESSES = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cultural-sleep",
   "metadata": {},
   "source": [
    "As a simple example, let's use the squaring of a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-transcript",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    return x**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "serious-change",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mp.Pool(N_PROCESSES) as pool:\n",
    "    output = pool.map(f, [1, 2, 3])\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "north-serial",
   "metadata": {},
   "source": [
    "Great, that works. But what if we want to have a more general f(x), like being able to choose the exponent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-species",
   "metadata": {},
   "outputs": [],
   "source": [
    "def g(x, n):\n",
    "    return x**n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "confident-happening",
   "metadata": {},
   "source": [
    "Let's calulcate $1^3, 2^3, 3^3$, i.e. $n=3$ for all cases. In the above example, this could be our parameter set `params`.\n",
    "\n",
    "We might assume that we can pass a tuple or a list, but this fails:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formed-yield",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mp.Pool(N_PROCESSES) as pool:\n",
    "    output = pool.map(g, [(1,2), (2,3), (3,3)])\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dimensional-hepatitis",
   "metadata": {},
   "source": [
    "Instead, we need to wrap our function into a partial function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wound-india",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "\n",
    "partial_run = functools.partial(g, n=3) # this instantiates a copy of g with one argument less\n",
    "partial_run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "celtic-monte",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mp.Pool(N_PROCESSES) as pool:\n",
    "    output = pool.map(partial_run, [1, 2, 3])\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranking-reggae",
   "metadata": {},
   "source": [
    "**Final task:** implement multiprocessing into `standalone_script.py`. To do so, divide the total population into `N_PROCESSES` subpopulations, and run these in parallel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respiratory-collectible",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
